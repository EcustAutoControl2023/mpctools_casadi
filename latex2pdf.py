#!/usr/bin/env python

# Help message is automatically generated by argparse module. Invoke from a
# terminal to see all available options.
r"""
Adapted from the bash script latex2pdf, this script tries to automatically run
pdflatex, bibtex, and makeindex enough times to get everything resolved. It
is quite solid for simple documents (i.e., a single .tex file with no \include
statements), but for larger projects, it may run some things more than it
needs to.

The added bonus here over the latex2pdf bash script is that we now check all of
the included bibliography files to see if the corresponding bbl need to be
updated. This means that if you change a bib file and then run this script, the
bibliography changes will actually show up in your document. This didn't happen
before.

If you're using a package that requires multiple pdflatex runs (and it does not
output any standard warning message to tell you when you need to run pdflatex
again), then consider using the --min-runs option. This can make sure pdflatex
runs at least 2 times (or more).

Finally, there is a --paranoid option that will keep running pdflatex until
none of the aux files change. Note that if, for whatever reason, you are
printing a timestamp in the aux file, then this will break because aux files
never stop changing. 

Author: Michael Risbeck <risbeck@wisc.edu>
"""

import argparse
import collections
import hashlib
import itertools
import os
import re
import shlex
import string
import subprocess
import sys
import tempfile
DEBUG = False # Can be changed by command-line argument.

# Helper function for parser.
def getfilecheck(ext=None,directory=False,exists=True,toAbs=False):
    """
    Returns a funcion to check whether inputs are valid files/directories.
    """
    def filecheck(s):
        s = str(s)
        if toAbs:
            try:
                s = os.path.abspath(s)
            except: # Catch everything here.
                raise argparse.ArgumentTypeError("unable to get absolute path")
        if ext is not None and not s.endswith(ext):
            raise argparse.ArgumentTypeError("must have '%s' extension" % (ext,))
        if exists:
            if directory:
                if not os.path.isdir(s):
                    raise argparse.ArgumentTypeError("must be an existing directory")
            elif not os.path.isfile(s):
                raise argparse.ArgumentTypeError("must be an existing file")
        return s
    return filecheck

# Build the parser in the global namespace so everybody has access.
parser = argparse.ArgumentParser(add_help=False,description=
        "runs pdflatex, bibtex, etc. on a .tex file to produce a pdf",
        epilog=__doc__,formatter_class=argparse.RawDescriptionHelpFormatter)

optargs = parser.add_argument_group("normal options")
optargs.add_argument("--help",help="print this help",action="help")
optargs.add_argument("--dir",help="working directory to run pdflatex, etc.",
                    type=getfilecheck(directory=True,toAbs=True),
                    default=os.getcwd())
optargs.add_argument("--texinputs",help="extra directories for tex inputs (relative to DIR)",
                    action="append",default=[])
optargs.add_argument("--bibinputs", action="append", default=[],
                     help="extra directories for bib inputs (relative to DIR)")
optargs.add_argument("--min-runs",help="minimum number of pdflatex runs",
                    type=int,default=1)
optargs.add_argument("--max-runs",help="maximum number of pdflatex runs",
                    type=int,default=4)
optargs.add_argument("--display",help="set display level",
                    choices=set(["all","some","errors","none"]),
                    default="errors")

advargs = parser.add_argument_group("advanced options")
advargs.add_argument("--pdflatex",help="shell command for pdflatex",
                    default="pdflatex")
advargs.add_argument("--flags",help="flags to pdflatex",
                    default="--synctex=1  --halt-on-error")
advargs.add_argument("--paranoid",help="run until aux files do not change",
                    action="store_true")
advargs.add_argument("--check-all-aux", action="store_true",
                     help="consider all aux files in the directory, not just "
                     "those explicitly mentioned in the log file.")
advargs.add_argument("--recheck-aux",help="recheck for aux files after each pdflatex run",
                    action="store_true")
advargs.add_argument("--check-blx-timestamps",help="consider timestamps on -blx.bib files.",
                     action="store_true")
advargs.add_argument("--ignore-errors",help="try to plow through python/latex errors",
                    action="store_true")
advargs.add_argument("--debug",help="print extra debugging information",
                    action="store_true")
advargs.add_argument("--show-cite-errors",help="display missing citations as errors",
                     action="store_true")

reqargs = parser.add_argument_group("required arguments")
reqargs.add_argument("texfile",help="source .tex file",
                    type=getfilecheck(ext=".tex",toAbs=True))

parser.add_argument("--DEFAULT-FLAGS",help=argparse.SUPPRESS, # Don't show help for this one.
                    default="--interaction=nonstopmode")

# Create a namedtuple for storing aux file information.
AuxFile = collections.namedtuple("AuxFile", ["relpath","exists","timestamp","bibdata","md5"])

def main(*args):
    """
    Gets command line arguments as a list and runs the main script.

    Note that the name of the script is not needed as an argument; thus, to
    use arguments passed from the command line, this should be called as
    main(*sys.argv[1:]).
    """    
    global DEBUG    
    
    # Process arguments.
    options = vars(parser.parse_args(args))
    DEBUG = options["debug"]
    
    # Break out some arguments.
    crashonerror = not options["ignore_errors"]
    displayOptions = {
        #     (some display, error display, stdout)
        "none" : (False, False, os.devnull),
        "some" : (True, False, os.devnull),
        "errors" : (True, True, os.devnull),
        "all" : (True, True, None),
    }
    (somedisplay, errordisplay, stdout) = displayOptions[options["display"]]
    if stdout is not None:
        stdout = open(stdout,"w")  
    fullfilename = options["texfile"]
    fullbuilddir = options["dir"]
    maxruns = options["max_runs"] + options["paranoid"] # Add an extra run if paranoid flag.
    minruns = options["min_runs"]
    
    # Now it's time to actually run pdflatex and other stuff.
    (filedir, basefilename) = os.path.split(fullfilename)
    basefilename = basefilename[:-4] # Remove .tex extension.
    
    if DEBUG:
        print "*** Source file: %s ***" % (os.path.relpath(fullfilename, fullbuilddir),)
    
    extrafileext = ["log", "idx", "aux", "ind", "tex", "ctx", "ain", "and",
                    "cnd"]
    extrafile = {}
    for ext in extrafileext:
        extrafile[ext] = os.path.join(fullbuilddir,basefilename + "." + ext)
    
    # Figure out pdflatex arguments.
    pdflatexargs = [options["pdflatex"]] + shlex.split(options["flags"] + " " + options["DEFAULT_FLAGS"])

    # Also get environment variables for pdflatex. We need to change a variable
    # so that long filenames aren't broken across lines in the log file. We
    # use the same environment for bibtex as well.
    pdflatexenv = dict(os.environ, max_print_line="2048")
    for k in ["texinputs", "bibinputs"]:
        K = k.upper()
        pdflatexenv[K] = ":".join([pdflatexenv.get(K,"")] + options[k])
        if DEBUG:
            print "|  Set %s to '%s'" % (K, pdflatexenv[K])
    
    # Regexes to search log file.
    checks = [
        # (regex, number of lines, whether to display as error message)
        (r"LaTeX Warning:.*Rerun to get cross", 1, True),
        (r"Warning:.*Citation(s) may have changed", 1, True),
        (r"LaTeX Warning:.*Citation.*undefined", 1, options["show_cite_errors"]),
        (r"LaTeX Warning: Reference `.*' on page \d+ undefined", 1, False),
        (r"Warning:.*There were undefined (references|citations)", 1, True),
        (r"No file .*\.(bbl|toc|[aic]nd)", 1, True),
        (r"Package rerunfilecheck Warning: File.*has changed", 1, False),
        (r"LaTeX Error:", 1, True),
        (r"! Undefined control sequence", 2, True),
        (r"!  ==> Fatal error occurred", 1, True), 
    ]
    checks = [(re.compile(r), n, tf) for (r, n, tf) in checks]
    logregex = [(r, n) for (r, n, _) in checks] # All errors and warnings.   
    logerrorregex = [(r, n) for (r, n, tf) in checks if tf] # Just errors.
    
    # Regexes to search bib file.
    checks = [
        # (regex, number of lines)
        ("Repeated entry---line \d* of file", 4),
        ("Warning--I didn't find a database entry for", 1),
        ("I was expecting a .* or a .*---line \d* of file", 5),
        ("Warning--entry type for .* isn't style-file defined", 2),
        ("I couldn't open database file", 4),
    ]
    blgregex = [(re.compile(r), n) for (r, n) in checks]
    
    # Check aux file to see if there is an \inserttotalframenumber anywhere.
    beamer_numslides = checktotalslides(extrafile["aux"])
    
    # Build a list of index file extensions for, e.g., books with multiple
    # different types of indices.
    indexextensions = {
        # key : (input extension, output extension)    
        "subject" : ("idx", "ind"),        
        "author" : ("ain", "and"),
        "citation" : ("ctx", "cnd"),
    }
    
    # Now start the main loop.        
    runcount = 1
    keepgoing = True
    auxinfo = {}
    citationindex = None
    while keepgoing and runcount <= maxruns:
        # Run bibtex if any bib files are found.
        for (f,a) in auxinfo.iteritems():
            if len(a.bibdata) > 0:
                # We need to make sure each file is passed with a relative filename
                # or else bibtex will complain because it doesn't want to open any
                # files outside of its working directory. So, we check if the input
                # is an absolute path, and if so, we make it a relative path.
                if a.relpath.startswith(".."):
                    print (" !!! Warning: file <%s> is not within directory <%s>. "
                        "Bibtex will likely error." % (a.relpath,fullbuilddir))
                
                if somedisplay:
                    print "*** running bibtex on <%s> ***" % a.relpath
                bibtex = subprocess.Popen(["bibtex",a.relpath], 
                                          cwd=fullbuilddir, stdout=stdout,
                                          env=pdflatexenv)
                bibtex.wait()
                if bibtex.returncode != 0:
                    print "    !! bibtex error [Code %d]." % (bibtex.returncode,)
                    if errordisplay:
                        blgfile = re.sub("\\.aux$", ".blg", a.relpath)
                        try:
                            errs = grepfile(blgfile, blgregex, multiple=True)
                        except IOError:
                            errorout(message="Fatal bibtex error: %s missing."
                                % (blgfile,), usage=False, status=2)
                        else:
                            printerrors(errs, firstchar="    !!")
    
        # Get a list of all aux files in the build directory and information
        # including timestamps, any \bibdata entries, and possibly md5 sums.
        # We get the list of files from the previous auxinfo dict. If this is
        # the first run, we need a guess for all the auxiliary files we might
        # need. We first take all the files currently in the build directory.
        # Then, if the log file exists, we search for additional aux files. If
        # this is a subsequent run, we can just use the files found before.
        if runcount == 1:
            auxfiles = [extrafile["aux"]] + os.listdir(fullbuilddir)
            if os.path.isfile(extrafile["log"]):
                auxfiles += getauxfromlog(extrafile["log"], pdir=fullbuilddir)
        else:
            auxfiles = auxinfo.keys()
        oldauxinfo = getauxinfo(auxfiles, pdir=fullbuilddir,
                                md5=options["paranoid"])
        
        # Now run pdflatex.
        if somedisplay:
            print "*** running pdflatex (%d) ***" % runcount

        pdflatex = subprocess.Popen(pdflatexargs + [fullfilename],
                                    cwd=fullbuilddir,stdout=stdout,
                                    env=pdflatexenv)
        pdflatex.wait()
        keepgoing = (pdflatex.returncode != 0)
        if keepgoing:
            if somedisplay:
                print "    !! pdflatex error [Code %d]. Check log." % (pdflatex.returncode,)
            if errordisplay:
                errs = grepfile(extrafile["log"], logregex, multiple=True)
                printerrors(errs, firstchar="    !!")
        else:
            keepgoing = (runcount < minruns)
            if DEBUG:
                print "|  Haven't met minimum runs. Continuing."
        
        # Update info for aux files.
        auxfiles = [extrafile["aux"]] + getauxfromlog(extrafile["log"], pdir=fullbuilddir)
        if options["check_all_aux"]:
            auxfiles += os.listdir(fullbuilddir)
        newauxinfo = getauxinfo(auxfiles, pdir=fullbuilddir, md5=options["paranoid"])
        auxinfo = getmodifiedaux(oldauxinfo, newauxinfo, md5=options["paranoid"])
        
        # If first time, check log file to get auxiliary files with bibliographies.
        # Also check to see if the number of slides has changed.
        if (runcount == 1 or options["recheck_aux"]) and not keepgoing:
            kwargs = dict(includeblx=options["check_blx_timestamps"],
                          env=pdflatexenv)
            (outofdate, fullbib) = biboutofdate(auxinfo, fullbuilddir,
                                                **kwargs)
            if outofdate:
                keepgoing = True
                if DEBUG:
                    print "|  bbl files out of date. Need to rebuild."
            
            if (beamer_numslides is not None or options["recheck_aux"]) and not keepgoing:
                new_beamer_numslides = checktotalslides(extrafile["aux"])
                if new_beamer_numslides != beamer_numslides:
                    beamer_numslides = new_beamer_numslides                    
                    keepgoing = True
                    if DEBUG:
                        print "|  Number of slides has changed."
            
        # Now loop through aux files to see if bibinfo is different. Also, check
        # check md5 if the paranoid flag.
        if not keepgoing or DEBUG:
            for (f,a) in auxinfo.iteritems():
                if len(a.bibdata) > 0:
                    if f in oldauxinfo and oldauxinfo[f].bibdata != a.bibdata:
                        keepgoing = True
                        if DEBUG:
                            print "|  bibdata changed in '%s'. Running again." % (a.relpath,)
                if not keepgoing and options["paranoid"]:
                    if f not in oldauxinfo:
                        keepgoing = True
                        if DEBUG:
                            print "|  aux file '%s' is new. Running again." % (a.relpath,)
                    elif oldauxinfo[f].md5 != a.md5:
                        keepgoing = True
                        if DEBUG:
                            print "|  md5 of '%s' has changed. Running again." % (a.relpath,)
                if not keepgoing:
                    break
        
        # Check all index files and make sure they are older than the tex file.
        if not keepgoing or DEBUG:        
            for (_, ext) in indexextensions.itervalues():
                textime = getmtime(extrafile["tex"])
                indextime = getmtime(extrafile[ext], na=float("inf"))
                if textime >= indextime:
                    keepgoing = True
                    if DEBUG:
                        print "|  %s file is out of date. Running again" % ext  
        
        # Finally, check log for errors to see if we need to keep going.
        if not keepgoing or DEBUG:
            errs = grepfile(extrafile["log"], logregex, multiple=True)
            if len(errs) > 0:
                keepgoing = True
                if DEBUG:
                    printerrors(errs)
                elif errordisplay and runcount == maxruns:
                    printerrors(errs, firstchar="    !! ")
        
        # Run makeindex if there should be an index. Note that there are
        # multiple types of indices, with special behavior for the "author"
        # index.            
        if keepgoing:
            for (indextype, (inext, outext)) in indexextensions.iteritems():
                if os.path.isfile(extrafile[inext]):
                    if DEBUG:
                        print "| building %s file." % outext
                    
                    # If this is an author index, we have to run authorindex first.
                    if indextype == "author":
                        if somedisplay:
                            print "*** running authorindex ***"
                        auxfiles = auxinfo.keys()
                        args = ["authorindex", "-i", "-r", basefilename] + auxfiles
                        makeauthor = subprocess.Popen(args, cwd=fullbuilddir,
                                                      stdout=stdout, stderr=stdout)
                        makeauthor.wait()
                        
                    elif indextype == "citation":
                        if somedisplay:
                            print "*** cleaning citation index ***"
                        if citationindex is None:
                            citationindex = CitationIndex()
                        citationindex.clean(extrafile[inext])
                        
                    # Now run makeindex.                    
                    if somedisplay:
                        print "*** running makeindex ***"
                    [relin, relout] = [os.path.relpath(extrafile[k], fullbuilddir)
                                       for k in [inext, outext]]
                    if relin.startswith(".."):
                        print (" !!! Warning: file <%s> is not within directory <%s>. "
                               "Makeindex will likely error." % (relin, fullbuilddir))
                    args = ["makeindex", "-o", relout, relin]
                    makeindex = subprocess.Popen(args, cwd=fullbuilddir, stdout=stdout,
                                                 stderr=stdout) # Makeindex uses stderr
                    makeindex.wait()                   
        
        # Increment run counter.            
        runcount += 1
    
    if runcount > maxruns and keepgoing:
        errorout("Errors persist after %d runs" % (runcount - 1),doc=False,usage=False,crash=crashonerror)
    elif crashonerror:
        if DEBUG:
            print "*** Successful completion. ***"
        sys.exit(0) # Successful completion.


# Some helper functions.
def errorout(message="Invalid Usage",status=1,doc=False,usage=True,crash=True):
    """
    Prints docstring and exits with status 1.
    """
    print "*** %s ***" % message
    if doc:
        parser.print_help()
    elif usage:
        parser.print_usage()
    if crash:
        sys.exit(status)


def getauxinfo(files=None, pdir=".", md5=False, ext=".aux"):
    """
    Returns a dictionary with AuxFile named tuples for each element of files.
    
    If files is None, gets a list of all files in pdir.
    """
    if files is None:
        files = os.listdir(pdir)
    files = getfullpaths(files, pdir)
    auxinfo = {}
    for f in files:
        if f.endswith(ext):
            relpath = os.path.relpath(f,pdir)
            exists = os.path.isfile(f)
            if exists:
                timestamp = os.path.getmtime(f)
                bibdata = getbibdata(f)
                md5 = md5sum(f) if md5 else None
            else:
                timestamp = None
                bibdata = tuple()
                md5 = None
            auxinfo[f] = AuxFile(relpath,exists,timestamp,bibdata,md5)
    return auxinfo


def getmodifiedaux(old,new,md5=False):
    """
    Returns AuxFile for files changed in new.
    
    Files not in old, files strictly newer than their counterparts in old, or
    (if md5 is True), files whose md5 sums do not match in old.
    """
    changed = {}
    for (f,aux) in new.iteritems():
        if f not in old or aux.timestamp > old[f].timestamp or (md5 and aux.md5 != old[f].md5):
            changed[f] = aux
    return changed


def getauxfromlog(log, pdir=""):
    """
    Scans through the log file and looks for aux files.
    
    Returns a list of absolute paths to aux files.
    
    Only returns a given file if it exists (with relative paths taken relative
    to pdir).
    """
    aux = set()
    auxre = re.compile(r"\((\.?/.*?\.aux)")
    with open(log,"r") as f:
        if DEBUG:
            print "|  Opening log file <%s>." % (log,)
        for line in f:
            for a in auxre.findall(line):
                a = os.path.normpath(os.path.join(pdir, a))
                if os.path.isfile(a):
                    aux.add(a)
    return list(aux)


def getbibdata(filename):
    """
    Searches filename for \bibdata{*} and returns bibliography files.
    """
    bibfiles = []
    f = open(filename,"r")
    for line in f:
        m = re.match(r"\\bibdata\{(.*)\}",line)
        if m is not None:
            bibfiles.append(tuple([b.strip() + ".bib" for b in m.group(1).split(",")]))
    bibfiles = tuple(itertools.chain.from_iterable(bibfiles))
    return bibfiles


def biboutofdate(auxinfo, pdir, includeblx=True, env=None):
    """
    Check timestamps on bib files to see if bbl files need to be remade.
    
    Returns a tuple whose first entry is True/False to say whether the
    bibliography is out of date, and whose second entry is a list of full
    bibliography filenames.
    """
    # Need to check any included bib files to see if they have been modified.
    bib = list(itertools.chain.from_iterable((a.bibdata for a in auxinfo.values())))
    if not includeblx:
        bib = filter(lambda b : not b.endswith("-blx.bib"), bib)
    if len(bib) == 0:
        # Nothing to do.
        outofdate = False
        bibfull = []
    else:
        # Get list of bib files and last modified timestamps.
        bibfull = kpsewhich(bib, pdir, env=env)        
        bibtimes = [getmtime(f) for f in bibfull]
        newestbib = safemax(bibtimes)            
        
        # Get a list of the .bbl files and timestamps.
        bblfull = [re.sub(".aux$",".bbl",f) for f in auxinfo]
        bbltimes = [getmtime(f, na=float("inf")) for f in bblfull]
        oldestbbl = safemin(bbltimes)
                    
        # Now compare timestamps and decide what to do.
        outofdate = (newestbib >= oldestbbl) # Whether or not everything is in date.
    return (outofdate, bibfull)


def kpsewhich(biblist, cwd=".", env=None):
    """
    Runs kpsewhich on a list of bib files and returns full paths for each.
    """            
    kpse = subprocess.Popen(["kpsewhich"] + biblist, cwd=cwd,
                            stdout=subprocess.PIPE, env=env)
    (bibfullraw, kpsewhicherr) = kpse.communicate()
    bibfull = getfullpaths(bibfullraw.split("\n"), pdir=cwd)
    return bibfull

    
def grepfile(filename, regexes, multiple=False, multiline=True):
    """
    Search a file using a number of regexes and returns first match.
    
    regexes should be a list of (regex, int) pairs, with the int giving the
    number of lines included in this error message. Alternatively, if
    multiline is False, regexes is just a list of the regexes, all assumed
    to take only one line.
    
    If multiple is true, return a list of all matches (possibly empty)
    
    regexes should be a list of compiled regular expressions.
    """
    if multiline == False:
        regexes = [(r, 1) for r in regexes]
    match = None
    matches = []
    readfile = open(filename,"r")
    for line in readfile:
        for (regex, numlines) in regexes:
            m = regex.search(line)
            if m is not None:
                match = [line.strip("\n")]
                for n in range(numlines - 1):
                    match.append(next(readfile, "").strip("\n"))
                match = tuple(match) if multiline else match[0]
                if multiple:
                    matches.append(match)    
                else:
                    break
    return matches if multiple else match


def getmtime(f, na=-float("inf")):
    """
    Wrapper to os.path.getmtime, returning -inf if a file doesn't exist.
    
    The optional argument na controls what is returned for files that don't
    exist.
    """
    try:
        t = os.path.getmtime(f)
    except OSError:
        t = na
    return t


def getfullpaths(files,pdir=None,empty=False):
    """
    Gets full file names for each element of files using pdir as the prefix for relative paths."
    
    Set empty=True to still include empty strings in files. Otherwise, they are skipped.
    """
    minlen = 0 if empty else 1
    if pdir is None:
        pdir = os.getcwd()
    return [os.path.normpath(os.path.join(pdir,f.strip())) for f in files if len(f) >= minlen]


def safemax(x,empty=-float("inf")):
    """
    Maximum of list x with optional value in case x is empty (default: -inf).
    """
    if len(x) == 0:
        return empty
    else:
        return max(x)

        
def safemin(x,empty=float("inf")):
    """
    Minimum of list x with optional value in case x is empty (default: inf).
    """
    if len(x) == 0:
        return empty
    else:
        return min(x)


def checktotalslides(auxfile):
    """
    Scans an aux file for \inserttotalframenumber and returns number of frames.
    
    If aux file doesn't exist, or if there is no \inserttotalframenumber, then
    returns None.
    """
    retval = None
    if os.path.isfile(auxfile):
        f = open(auxfile,"r")
        line = "TEMP"
        while len(line) > 0:
            line = f.readline()
            m = re.search(r"\\inserttotalframenumber\s\{(\d+)\}",line)
            if m is not None:
                retval = int(m.group(1))
                if DEBUG:
                    print "|  Found inserttotalframenumber: %s" % (retval,)
    return retval


def md5sum(filename,block=128):
    """
    Returns md5 digest of a file.
    """
    md5 = hashlib.md5()
    with open(filename, "rb") as f:
        for chunk in iter(lambda: f.read(block*md5.block_size),""):
            md5.update(chunk)
    return md5.hexdigest()


def printerrors(errs, firstchar="|  ", errchar=">"):
    """
    Prints each error message in the list errs.
    """
    if len(errs) > 0:
        print "%sFound the following error messages:" % (firstchar,)
        prompt = "\n%s%s " % (firstchar, errchar)
        joinstr = "\n" + " "*(len(prompt) - 1)        
        print prompt.join([""] + [joinstr.join(e) for e in errs]).strip("\n")

# Class to properly format the citation index.
class CitationIndex(object):
    """Functions to help make a clean citation index."""
    def __init__(self):
        """Compiles all necessary regexes."""
        self.entryre = re.compile(r"\\indexentry \{\{(?P<author>.*?)\}\\ "
                                   "(?P<year>.*?)\}\{(?P<page>.*?)\}")
        self.tokenre = re.compile(r"\\[^ \{] ?")
        
        self.spaceafterre = re.compile(r"\{\s+")
        self.spacebeforere = re.compile(r"\s+\}")

        self.keeptext = set(string.ascii_letters + string.digits + " ")
        
        self.replacements = [
            (r"\OE", "OE"),
            (r"\aa", "a"),
            (r"\O", "O"),
            (r"\o", "o"),
            (r"\ss", "s"),
            (r"\ae", "ae"),
            (r"\AA", "A"),
            (r"\L", "L"),
            (r"\l", "l"),
            (r"\oe", "oe"),
            (r"\ae", "AE"),
            ("~", " ")
        ]
    
    def nobracespace(self, s):
        """
        Gets rid of whitespace immediately inside braces.
        """
        s = self.spacebeforere.sub("{", s)
        s = self.spaceafterre.sub("}", s)
        return s

    def keep(self, s):
        """Returns true or false whether s is in KEEPTEXT."""
        return (s in self.keeptext)

    def purify(self, name):
        """
        Returns "purified" version of name.
        """
        name = self.nobracespace(name)
        for (find, repl) in self.replacements:
            name = name.replace(find, repl)
        name = self.tokenre.sub("", name)
        name = filter(self.keep, name)
        return name.upper()

    def clean(self, infilename, outfilename=None):
        """
        Makes a clean citationindex from infile.
        """
        # Choose output file.
        if outfilename is None:
            indir = os.path.split(infilename)[0]
            kwargs = dict(dir=indir, prefix="authorindex_", delete=False)
            getoutfile = lambda : tempfile.NamedTemporaryFile("w", **kwargs)
        else:
            getoutfile = lambda : open(outfilename, "w")
        
        # Do main loop.        
        with open(infilename, "r") as infile, getoutfile() as outfile:
            if DEBUG:
                print "|  opened file %s for citationindex." % outfile.name
            for (i, line) in enumerate(infile):
                match = self.entryre.search(line)
                if match is not None:
                    name = match.group("author")
                    nicename = self.purify(name)
                    year = match.group("year")
                    niceyear = self.purify(year)
                    page = match.group("page")
                    
                    key = r"{%s}\ %s" % (name, year)
                    nicekey = " ".join([nicename, niceyear])
                                
                    entry = r"\indexentry{%s@%s}{%s}" % (nicekey, key, page)
                    outfile.write(entry + "\n")
                else:
                    raise RuntimeError("No match on line %d.")
            if outfilename is None:
                outfiletmp = outfile.name
            else:
                outfiletmp = None
        
        # Overwrite input file if no output file name was given.
        if outfiletmp is not None:
            if DEBUG:
                print "|  renaming %s to %s" % (outfiletmp, infilename)
            os.rename(outfiletmp, infilename)

# Finally, run main file.
if __name__ == "__main__":
    main(*sys.argv[1:])
